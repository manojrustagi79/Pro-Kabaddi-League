{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapped Data for Point Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"1\",\"2\",\"3\",\"4\",\"8\",\"26\",\"49\"]\n",
    "url_pts = \"https://www.prokabaddi.com/sifeeds/kabaddi/live/json/{}_standing.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(dic, c_df):\n",
    "    if type(dic) is dict:\n",
    "        for key,value in dic.items():\n",
    "            if key == \"team\":\n",
    "                if isinstance(dic[key],(list,tuple)):\n",
    "                    df1 = pd.DataFrame()\n",
    "                    for i in range(0,len(dic[key])):\n",
    "                        item = value[i]\n",
    "                        di = {}\n",
    "                        for k,va in item.items():\n",
    "                            if k == \"match_result\":\n",
    "                                break;\n",
    "                            if k in di:\n",
    "                                print(\"yes\")\n",
    "                               # di[k].append(va)\n",
    "                            else:\n",
    "                                di[k] = va\n",
    "\n",
    "                        tb = json_normalize(di)\n",
    "                        if len(c_df) >0:\n",
    "                            c_df = pd.concat([c_df, tb])\n",
    "                        else:\n",
    "                            c_df = tb\n",
    "\n",
    "                    return c_df\n",
    "                else:\n",
    "                    table = json_normalize(dic[key])\n",
    "            else:\n",
    "                c_df = parse(dic[key],c_df)\n",
    "\n",
    "    elif isinstance(dic,(tuple,list)):\n",
    "        for i in range(0,len(dic)):\n",
    "            item = dic[i]\n",
    "            c_df = parse(item,c_df)\n",
    "    else:\n",
    "        print(\"not x:\",dic)\n",
    "    return c_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not x: 1\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Jul 19, 2019\n",
      "not x: 0\n",
      "not x: \n",
      "not x: 2\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Jul 19, 2019\n",
      "not x: 0\n",
      "not x: \n",
      "not x: 3\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Jul 19, 2019\n",
      "not x: 0\n",
      "not x: \n",
      "not x: 4\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Jul 19, 2019\n",
      "not x: 0\n",
      "not x: \n",
      "not x: 8\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Jul 19, 2019\n",
      "not x: 3\n",
      "not x: Zone A\n",
      "not x: 4\n",
      "not x: Zone B\n",
      "not x: 26\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Jul 19, 2019\n",
      "not x: 3\n",
      "not x: Zone A\n",
      "not x: 4\n",
      "not x: Zone B\n",
      "not x: 49\n",
      "not x: 1\n",
      "not x: 0\n",
      "not x: Sep 29, 2019\n",
      "not x: 0\n",
      "not x: \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(0, len(url_list)):\n",
    "    jsonData = requests.get(url_pts.format(url_list[i])).json()\n",
    "    jsons = jsonData\n",
    "    table = jsonData[\"standings\"]\n",
    "    df2 = pd.DataFrame()\n",
    "    df2 = parse(table, df2)\n",
    "    df2[\"season\"] =i+1\n",
    "    if len(df) > 0:\n",
    "        df = pd.concat([df,df2])\n",
    "    else:\n",
    "        df = df2\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"point_table.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"1_1\",\"1_2\",\"1_3\",\"1_4\",\"1_8\",\"1_26\",\"1_49\"]\n",
    "\n",
    "team_won = [3,5,6,6,6,1,0]\n",
    "\n",
    "feature_list= [\"96\",\"133\",\"140\",\"13\",\"97\",\"98\",\"15\",\"95\",\"99\",\"134\",\"20\",\"135\",\"136\",\"137\"]\n",
    "\n",
    "feature_name = [\"total_points_scored\", \"total_points_conceded\",\"avg_points_scored\",\"successful_raids\",\"raid_points\",\"avg_raid_points\",\"successful_tackles\",\n",
    "               \"tackle_points\", \"avg_tackle_points\",\"super_raid\",\"super_tackles\",\"do_or_die_raid_points\",\"all_outs_inflicted\",\"all_outs_conceded\" ]\n",
    "url = \"https://www.prokabaddi.com/sifeeds/kabaddi/static/json/{}_{}_stats.json\"\n",
    "prev_tab = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "2 11\n",
      "2 12\n",
      "2 13\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "3 10\n",
      "3 11\n",
      "3 12\n",
      "3 13\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "4 10\n",
      "4 11\n",
      "4 12\n",
      "4 13\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "5 10\n",
      "5 11\n",
      "5 12\n",
      "5 13\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "6 10\n",
      "6 11\n",
      "6 12\n",
      "6 13\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(url_list)):\n",
    "\n",
    "    #jsonData = requests.get(url.format(url_list[i])).json()\n",
    "    prev_col = pd.DataFrame()\n",
    "    for j in range(0, len(feature_list)):\n",
    "        print(i,j)\n",
    "        url_s = url.format(url_list[i],feature_list[j])\n",
    "        jsonData = requests.get(url_s).json()\n",
    "        table = json_normalize(jsonData['data'])\n",
    "        table.rename(columns = {'value':feature_name[j]}, inplace = True)\n",
    "        table.rename(columns = {'rank':feature_name[j]+\"_rank\"}, inplace = True)\n",
    "        table.rename(columns = {'match_played':feature_name[j]+\"_match_played\"}, inplace = True)\n",
    "        if len(prev_col) > 0:\n",
    "            prev_col = pd.merge(prev_col,table,on=[\"team_id\",\"team_name\"])\n",
    "        else:\n",
    "            prev_col = table\n",
    "\n",
    "    prev_col[\"season\"] = i+1\n",
    "    \n",
    "    team = team_won[i]\n",
    "    \n",
    "    prev_col['winner'] = prev_col[\"team_id\"].apply(lambda x: 1 if x == team else 0)\n",
    "    \n",
    "    if len(prev_tab) >0 :\n",
    "        prev_tab = pd.concat([prev_col,prev_tab])\n",
    "    else:\n",
    "        prev_tab = prev_col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"team.csv\"\n",
    "prev_tab.to_csv(file_name, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Point table Data and Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 47)\n",
      "(68, 27)\n",
      "   Unnamed: 0  total_points_scored_match_played  total_points_scored_rank  \\\n",
      "0           0                                19                         1   \n",
      "1           1                                19                         2   \n",
      "2           2                                19                         3   \n",
      "3           3                                20                         4   \n",
      "4           4                                19                         5   \n",
      "\n",
      "   team_id          team_name  total_points_scored  \\\n",
      "0        2  Dabang Delhi K.C.                  709   \n",
      "1        4    Bengal Warriors                  676   \n",
      "2        1    Bengaluru Bulls                  656   \n",
      "3        7      Puneri Paltan                  652   \n",
      "4       28   Haryana Steelers                  650   \n",
      "\n",
      "   total_points_conceded_match_played  total_points_conceded_rank  \\\n",
      "0                                  19                           7   \n",
      "1                                  19                          10   \n",
      "2                                  19                           3   \n",
      "3                                  20                           1   \n",
      "4                                  19                           6   \n",
      "\n",
      "   total_points_conceded  avg_points_scored_match_played  ...  \\\n",
      "0                    617                              19  ...   \n",
      "1                    590                              19  ...   \n",
      "2                    644                              19  ...   \n",
      "3                    723                              20  ...   \n",
      "4                    626                              19  ...   \n",
      "\n",
      "   do_or_die_raid_points_rank  do_or_die_raid_points  \\\n",
      "0                          10                     47   \n",
      "1                           9                     51   \n",
      "2                          12                     42   \n",
      "3                           6                     60   \n",
      "4                           2                     71   \n",
      "\n",
      "   all_outs_inflicted_match_played  all_outs_inflicted_rank  \\\n",
      "0                               19                        1   \n",
      "1                               19                        2   \n",
      "2                               19                        6   \n",
      "3                               20                       10   \n",
      "4                               19                        4   \n",
      "\n",
      "   all_outs_inflicted  all_outs_conceded_match_played  all_outs_conceded_rank  \\\n",
      "0                  33                              19                      12   \n",
      "1                  31                              19                      11   \n",
      "2                  21                              19                       3   \n",
      "3                  18                              20                       1   \n",
      "4                  27                              19                       9   \n",
      "\n",
      "   all_outs_conceded  season  winner  \n",
      "0                 15       7       0  \n",
      "1                 16       7       0  \n",
      "2                 24       7       0  \n",
      "3                 33       7       0  \n",
      "4                 21       7       0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_team = pd.read_csv(\"team.csv\", sep='\\t')\n",
    "df_point = pd.read_csv(\"point_table.csv\", sep='\\t')\n",
    "\n",
    "print(df_team.shape)\n",
    "print(df_point.shape)\n",
    "\n",
    "print(df_team.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.merge(df_team,df_point, on=['team_id','team_name','season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.drop(columns=\"Unnamed: 0_x\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.drop(columns=\"Unnamed: 0_y\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv(\"team_data.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
